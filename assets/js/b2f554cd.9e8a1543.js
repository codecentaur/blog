"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[477],{10:e=>{e.exports=JSON.parse('{"blogPosts":[{"id":"adding-learner","metadata":{"permalink":"/blog/adding-learner","editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/blog/2024-07-30-adding-learner.md","source":"@site/blog/2024-07-30-adding-learner.md","title":"Adding Learner","description":"In this post, I\'m going to describe building a simple neural network using PyTorch that learns to add two numbers.","date":"2024-07-30T00:00:00.000Z","formattedDate":"July 30, 2024","tags":[{"label":"math-learner","permalink":"/blog/tags/math-learner"}],"readingTime":2.84,"hasTruncateMarker":true,"authors":[],"frontMatter":{"slug":"adding-learner","title":"Adding Learner","tags":["math-learner"]},"unlisted":false},"content":"In this post, I\'m going to describe building a simple neural network using PyTorch that learns to add two numbers.\\n\\n### Data Generation\\n\\nFirst, I\'ll define a method that generates the data. This method returns two tensors. The first tensor, `x`, is the input to the model, and the second tensor, `y`, is the expected output (the sum of the pairs of numbers).\\n\\n```python\\ndef generate_data(num_samples=1000):\\n    x = torch.randint(0, 100, (num_samples, 2), dtype=torch.float32)\\n    y = torch.sum(x, dim=1, keepdim=True)\\n    return x, y\\n```\\n\x3c!--truncate--\x3e\\n\\n### Defining the Model\\n\\nNext, I\'ll define a simple neural network module. This module has two linear layers with a ReLU activation function between them. The first layer takes two inputs, and the second layer outputs one value.\\n\\n```python\\nclass SimpleAdder(nn.Module):\\n    def __init__(self):\\n        super(SimpleAdder, self).__init__()\\n        self.fc1 = nn.Linear(2, 10)\\n        self.fc2 = nn.Linear(10, 1)\\n    \\n    def forward(self, x):\\n        x = torch.relu(self.fc1(x))\\n        x = self.fc2(x)\\n        return x\\n```\\n\\n### Training the Model\\n\\nHere\'s the method to train the model. Every 100 epochs, the training loss is printed to track progress.\\n\\n```python\\ndef train_model(model, criterion, optimizer, x_train, y_train, num_epochs=1000):\\n    for epoch in range(num_epochs):\\n        # Forward pass\\n        outputs = model(x_train)\\n        loss = criterion(outputs, y_train)\\n        \\n        # Backward pass and optimization\\n        optimizer.zero_grad()\\n        loss.backward()\\n        optimizer.step()\\n        \\n        if (epoch+1) % 100 == 0:\\n            print(f\'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\')\\n```\\n\\n### Testing the Model and Calculating Accuracy\\n\\nNext, I\'ll define a couple of methods to test the model and calculate accuracy. The model returns a number with a fractional part, which is useful for training because it gives the loss function a smoother gradient. When actually computing accuracy, I round the predictions to compare them with the whole number answers.\\n\\n```python\\ndef test_model(model, x_test):\\n    with torch.no_grad():\\n        predicted = model(x_test)\\n        rounded_predicted = torch.round(predicted)\\n    return rounded_predicted\\n\\ndef calculate_accuracy(predictions, targets):\\n    correct = (predictions == targets).sum().item()\\n    total = targets.size(0)\\n    accuracy = correct / total * 100\\n    return correct, total, accuracy\\n```\\n\\n## Main Function\\n\\nHere\'s the main function that puts everything together.\\n\\n```python\\n# Generate training and test data\\nx_train, y_train = generate_data(1000)\\nx_test, y_test = generate_data(10)\\n    \\n# Initialize the model, criterion, and optimizer\\nmodel = SimpleAdder()\\ncriterion = nn.MSELoss()\\noptimizer = optim.Adam(model.parameters(), lr=0.01)\\n    \\n# Train the model\\ntrain_model(model, criterion, optimizer, x_train, y_train)\\n    \\n# Test the model\\ny_pred = test_model(model, x_test)\\n    \\n# Calculate accuracy\\ncorrect, total, accuracy = calculate_accuracy(y_pred, y_test)\\n    \\n# Print results\\nprint(f\'Predictions:\\\\n{y_pred}\')\\nprint(f\'Actual sums:\\\\n{y_test}\')\\nprint(f\'Number of exactly correct predictions: {correct}/{total}\')\\nprint(f\'Accuracy: {accuracy:.2f}%\')\\n```\\n\\n### Output and Results\\n\\nHere is the output. The neural network shows that it is learning by the decreasing loss values.\\n\\n```\\nEpoch [100/1000], Loss: 2.5868\\nEpoch [200/1000], Loss: 0.3593\\nEpoch [300/1000], Loss: 0.2960\\nEpoch [400/1000], Loss: 0.2394\\nEpoch [500/1000], Loss: 0.1914\\nEpoch [600/1000], Loss: 0.1523\\nEpoch [700/1000], Loss: 0.1209\\nEpoch [800/1000], Loss: 0.0965\\nEpoch [900/1000], Loss: 0.0771\\nEpoch [1000/1000], Loss: 0.0615\\n```\\n\\nAfter the model has finished training, here are the results of running it on the test set.\\n\\n```\\nPredictions:\\ntensor([[ 64.],\\n        [131.],\\n        [114.],\\n        [ 82.],\\n        [ 86.],\\n        [ 47.],\\n        [ 76.],\\n        [ 32.],\\n        [112.],\\n        [ 17.]])\\n\\nActual sums:\\ntensor([[ 64.],\\n        [131.],\\n        [114.],\\n        [ 82.],\\n        [ 86.],\\n        [ 47.],\\n        [ 76.],\\n        [ 32.],\\n        [112.],\\n        [ 17.]])\\n\\nNumber of exactly correct predictions: 10/10\\nAccuracy: 100.00%\\n```\\n\\n### Wrap-up\\n\\nThis simple neural network successfully learned to add two numbers. The final accuracy on the test set is 100%, indicating that the model perfectly predicted the sum of the test input pairs. This example demonstrates the basic workflow of creating and training a neural network in PyTorch."}]}')}}]);